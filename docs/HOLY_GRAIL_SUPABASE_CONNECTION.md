# ğŸ† Holy Grail Supabase Connection

Last Updated: November 26, 2025

## The Secret That Works

After extensive troubleshooting, here's the **exact connection method** that successfully connects to Supabase production:

### âœ… The Working Connection String

```bash
postgresql://postgres:YOUR_PASSWORD@db.PROJECT_REF.supabase.co:5432/postgres
```

### ğŸ”‘ Key Discovery

**Use `postgres` as the username, NOT `postgres.PROJECT_REF`**

**Wrong (doesn't work):**
```bash
postgresql://postgres.nxjhqibnlbwzzphewncj:PASSWORD@db.nxjhqibnlbwzzphewncj.supabase.co:5432/postgres
```

**Right (works!):**
```bash
postgresql://postgres:wZnargrTWlMtyC5A@db.nxjhqibnlbwzzphewncj.supabase.co:5432/postgres
```

## Pull Production Schema

### Method 1: Direct pg_dump (Recommended - No Migration History Issues)

```bash
cd /Users/jordanbuckingham/Desktop/vibrationfit

# Use PostgreSQL 17 pg_dump for production database
/opt/homebrew/opt/postgresql@17/bin/pg_dump \
  "postgresql://postgres:wZnargrTWlMtyC5A@db.nxjhqibnlbwzzphewncj.supabase.co:5432/postgres" \
  --schema-only --no-owner --no-acl \
  > supabase/COMPLETE_SCHEMA_DUMP.sql
```

âœ… **Advantages:**
- No migration history conflicts
- Fast and direct
- Read-only operation
- Works even with version mismatches (with PG17 tools)

### Method 2: Supabase CLI (If Migration History Aligned)

```bash
# Full command that works
cd /Users/jordanbuckingham/Desktop/vibrationfit

supabase db pull --db-url "postgresql://postgres:PASSWORD@db.PROJECT_REF.supabase.co:5432/postgres"
```

### For VibrationFit Production

```bash
supabase db pull --db-url "postgresql://postgres:wZnargrTWlMtyC5A@db.nxjhqibnlbwzzphewncj.supabase.co:5432/postgres"
```

## What Made This Work

1. **Direct database connection** (not pooler)
2. **Simple username**: Just `postgres`
3. **Direct host**: `db.PROJECT_REF.supabase.co`
4. **Port**: `5432` (standard PostgreSQL port)
5. **IPv4 addon**: Must be enabled in Supabase settings
6. **PostgreSQL 17 tools**: If server is v17, use matching client version:
   ```bash
   brew install postgresql@17
   /opt/homebrew/opt/postgresql@17/bin/pg_dump ...
   ```

## Migration History Sync

If you get migration history mismatch errors, repair them:

```bash
# Mark migrations as reverted (if they don't exist locally)
supabase migration repair --status reverted YYYYMMDDHHMMSS --db-url "postgresql://postgres:PASSWORD@db.PROJECT_REF.supabase.co:5432/postgres"

# Mark migrations as applied (if they exist in production)
supabase migration repair --status applied YYYYMMDDHHMMSS --db-url "postgresql://postgres:PASSWORD@db.PROJECT_REF.supabase.co:5432/postgres"
```

## Clean Pull Strategy (Archive Everything)

If you want a fresh baseline from production:

```bash
# 1. Archive all local migrations
mv supabase/migrations/*.sql supabase/archive/

# 2. Clear remote migration history
supabase migration repair --status reverted MIGRATION_ID --db-url "CONNECTION_STRING"

# 3. Pull fresh from production
supabase db pull --db-url "CONNECTION_STRING"

# 4. Mark new baseline as applied
supabase migration repair --status applied NEW_MIGRATION_ID --db-url "CONNECTION_STRING"
```

## Prerequisites

- âœ… Supabase CLI installed and updated
- âœ… Logged in: `supabase login --token YOUR_ACCESS_TOKEN`
- âœ… IPv4 addon enabled in Supabase project
- âœ… Database password from Dashboard â†’ Settings â†’ Database

## Common Errors & Solutions

### "password authentication failed"
- âŒ Using wrong username format (`postgres.PROJECT_REF`)
- âœ… Use simple `postgres` username

### "connection refused"
- âŒ Using pooler URL instead of direct connection
- âœ… Use `db.PROJECT_REF.supabase.co:5432`

### "Unauthorized" when linking
- âŒ Not logged in or token expired
- âœ… Run `supabase login --token YOUR_TOKEN`

### "migration history does not match"
- âŒ Local migrations don't match production
- âœ… Use Method 1 (direct pg_dump) to avoid this issue
- âœ… Or use `supabase migration repair` to sync (only if needed)

### "server version mismatch" (e.g., server v17, local v14)
- âŒ Using older PostgreSQL client tools
- âœ… Install matching version: `brew install postgresql@17`
- âœ… Use versioned path: `/opt/homebrew/opt/postgresql@17/bin/pg_dump`

## Result

This method successfully:
- âœ… Connects to production database
- âœ… Pulls complete schema (278KB+ in our case)
- âœ… Creates clean baseline migration
- âœ… Syncs migration history

---

## ğŸ¯ Read-Only Schema Pull (For Documentation)

**Best Practice: Pull schema for reference without risking production changes**

### Step 1: Get Column Information (Safest)

```bash
cd /Users/jordanbuckingham/Desktop/vibrationfit

psql "postgresql://postgres:PASSWORD@db.PROJECT_REF.supabase.co:5432/postgres" -c "
SELECT 
  table_name,
  column_name,
  data_type,
  is_nullable,
  column_default
FROM information_schema.columns
WHERE table_schema = 'public'
ORDER BY table_name, ordinal_position
" > supabase/CURRENT_SCHEMA_COLUMNS.txt

echo "âœ… Schema reference saved"
```

**This is 100% read-only and completely safe!**

### Step 2: Get Full Schema Structure

```bash
# Pull schema as migration (won't be auto-applied)
supabase db pull --db-url "postgresql://postgres:PASSWORD@db.PROJECT_REF.supabase.co:5432/postgres"

# This creates: supabase/migrations/YYYYMMDDHHMMSS_remote_schema.sql
# Move it to documentation location
cp supabase/migrations/YYYYMMDDHHMMSS_remote_schema.sql supabase/COMPLETE_SCHEMA_DUMP.sql

# Archive the migration so it won't be accidentally pushed
mv supabase/migrations/YYYYMMDDHHMMSS_remote_schema.sql supabase/archive/
```

### Step 3: Document for Agents

Create `docs/PRODUCTION_SCHEMA_REFERENCE.md` with:
- Table descriptions
- Row counts
- Relationships
- Common queries

**Result:** Agents can see your schema without any risk of modifying production.

### What Gets Created:

| File | Purpose | Safe? |
|------|---------|-------|
| `supabase/COMPLETE_SCHEMA_DUMP.sql` | Full schema SQL | âœ… Reference only |
| `supabase/CURRENT_SCHEMA_COLUMNS.txt` | Column details | âœ… Reference only |
| `docs/PRODUCTION_SCHEMA_REFERENCE.md` | Human-readable docs | âœ… Reference only |

### Successful Example (November 16, 2025):

```bash
# 1. Got column info (read-only)
psql "CONNECTION_STRING" -c "SELECT table_name, column_name..." > supabase/CURRENT_SCHEMA_COLUMNS.txt
# Result: 112KB of column data, 939 lines

# 2. Pulled schema structure
supabase db pull --db-url "CONNECTION_STRING"
# Result: 278KB schema dump with 55 tables, 102 functions, 161 policies

# 3. Archived migration file
mv supabase/migrations/20251116122047_remote_schema.sql supabase/archive/
# Safe: Won't be accidentally pushed to production

# 4. Copied to reference location
cp supabase/archive/20251116122047_remote_schema.sql supabase/COMPLETE_SCHEMA_DUMP.sql
# Agents can now read schema without touching production
```

### Why This Approach is Safer:

1. **No migrations in active folder** - Can't accidentally push
2. **Documentation-focused** - Clear it's for reference
3. **Read-only queries** - Cannot modify data
4. **Archived originals** - History preserved

### To Update Schema Reference (Anytime):

```bash
# Just re-run the column query (100% safe)
psql "CONNECTION_STRING" -c "SELECT table_name, column_name..." > supabase/CURRENT_SCHEMA_COLUMNS.txt
```

**No risk, no changes to production, just updated docs!**

---

## ğŸ”’ Safety Rules

### âœ… Always Safe (Read-Only):
- `psql "CONNECTION" -c "SELECT ..."`
- `supabase db pull` (just pulls, doesn't apply)
- Reading schema information
- Viewing table structures

### âš ï¸ Use Carefully:
- `supabase migration repair` (changes migration tracking)
- Moving migration files
- Editing .sql files

### âŒ Never Run on Production:
- `supabase db reset` (DELETES EVERYTHING)
- `supabase db push` (applies migrations, could delete data)
- Any SQL with DELETE, TRUNCATE, DROP
- Anything you don't fully understand

---

**The Holy Grail:** Simple username `postgres`, direct connection, port 5432. Pull for docs, archive migrations, never push without approval. That's it! ğŸ‰

